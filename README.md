# ai-algorithms-project

AI algorithms implementation:

Lab1: ("L1-results") Implementation of an artificial neuron model. The operation of a perceptron was demonstrated using simple logic functions (AND, OR, NOT), and an example of learning for an arbitrary group of points was performed. Plots with the learning results were also included.

Lab2: ("L2-results") The process of training a single-layer network using the delta rule was carried out - a sub-problem for the examined training set was selected. The process of training the network using multi-layer perceptrons (MLP) with the backpropagation (BP) algorithm was performed. An attempt was made to train the XOR function with single and multi-layer networks, and a benchmark function with multi-layer networks. Class No. 3: (Folder "Wyniki 4-5")

Lab3: ("L3-results") Hebbian learning. The process of supervised and unsupervised network learning was carried out (during supervised learning, the same data was used as in the case of MLP).

Lab4: ("L4-results") Kohonen networks. A problem for clustering was defined. The Winner Takes All (WTA) rule was applied. The grouping process was carried out using a Kohonen network. Subsequently, network learning using an MLP network was performed.

Lab5: ("L5-results") Hopfield networks. A sub-problem of the examined data was defined, and the network learning process was carried out - attention was paid to the network's operation. Several patterns for which the network learning process was performed were determined. The result of the operation is a network that matches the signal to a specific pattern.
